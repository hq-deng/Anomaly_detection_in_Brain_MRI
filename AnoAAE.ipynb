{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "AnoAAE.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dQXZoszHJ791"
      },
      "source": [
        "You should open this .ipynb on Google Colab and choose GPU. Then, you can run this .ipynb step by step.\n",
        "\n",
        "\n",
        "**Requirements**\n",
        "\n",
        "Pytorch\n",
        "\n",
        "tensorboardX\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "awLq8yLPtvSN",
        "outputId": "14300438-f9b1-4cd8-f7b6-368dad822edf"
      },
      "source": [
        "!pip install tensorboardX"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting tensorboardX\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/af/0c/4f41bcd45db376e6fe5c619c01100e9b7531c55791b7244815bac6eac32c/tensorboardX-2.1-py2.py3-none-any.whl (308kB)\n",
            "\r\u001b[K     |█                               | 10kB 25.0MB/s eta 0:00:01\r\u001b[K     |██▏                             | 20kB 29.6MB/s eta 0:00:01\r\u001b[K     |███▏                            | 30kB 17.0MB/s eta 0:00:01\r\u001b[K     |████▎                           | 40kB 11.5MB/s eta 0:00:01\r\u001b[K     |█████▎                          | 51kB 7.5MB/s eta 0:00:01\r\u001b[K     |██████▍                         | 61kB 7.9MB/s eta 0:00:01\r\u001b[K     |███████▍                        | 71kB 7.8MB/s eta 0:00:01\r\u001b[K     |████████▌                       | 81kB 8.6MB/s eta 0:00:01\r\u001b[K     |█████████▌                      | 92kB 9.2MB/s eta 0:00:01\r\u001b[K     |██████████▋                     | 102kB 9.4MB/s eta 0:00:01\r\u001b[K     |███████████▊                    | 112kB 9.4MB/s eta 0:00:01\r\u001b[K     |████████████▊                   | 122kB 9.4MB/s eta 0:00:01\r\u001b[K     |█████████████▉                  | 133kB 9.4MB/s eta 0:00:01\r\u001b[K     |██████████████▉                 | 143kB 9.4MB/s eta 0:00:01\r\u001b[K     |████████████████                | 153kB 9.4MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 163kB 9.4MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 174kB 9.4MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 184kB 9.4MB/s eta 0:00:01\r\u001b[K     |████████████████████▏           | 194kB 9.4MB/s eta 0:00:01\r\u001b[K     |█████████████████████▎          | 204kB 9.4MB/s eta 0:00:01\r\u001b[K     |██████████████████████▎         | 215kB 9.4MB/s eta 0:00:01\r\u001b[K     |███████████████████████▍        | 225kB 9.4MB/s eta 0:00:01\r\u001b[K     |████████████████████████▍       | 235kB 9.4MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▌      | 245kB 9.4MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▌     | 256kB 9.4MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▋    | 266kB 9.4MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▋   | 276kB 9.4MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▊  | 286kB 9.4MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▊ | 296kB 9.4MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▉| 307kB 9.4MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 317kB 9.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: protobuf>=3.8.0 in /usr/local/lib/python3.6/dist-packages (from tensorboardX) (3.12.4)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from tensorboardX) (1.15.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from tensorboardX) (1.18.5)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.8.0->tensorboardX) (50.3.2)\n",
            "Installing collected packages: tensorboardX\n",
            "Successfully installed tensorboardX-2.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LuPCNcaPynNB"
      },
      "source": [
        "#EDA\n",
        "import sys\n",
        "import os\n",
        "import glob\n",
        "import random\n",
        "import time\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import cv2\n",
        "import matplotlib\n",
        "matplotlib.use('Agg')\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib import cm\n",
        "\n",
        "import argparse\n",
        "import math\n",
        "\n",
        "from torchvision import transforms\n",
        "from torchvision.utils import save_image\n",
        "\n",
        "from torch.utils.data import Dataset,DataLoader\n",
        "from torchvision import datasets\n",
        "\n",
        "import torch.autograd as autograd\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch\n",
        "import glob\n",
        "from PIL import Image\n",
        "from tensorboardX import SummaryWriter\n",
        "from sklearn.metrics import roc_auc_score,roc_curve,auc,precision_recall_curve,average_precision_score\n",
        "from sklearn import preprocessing "
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hyPMqobuKJbT"
      },
      "source": [
        "**Dataset:** The dataset is saved in Google Drive: \n",
        "\n",
        "https://drive.google.com/drive/folders/1PKPgkOkTBqQERUCvd0pWXtQx_64q0I34?usp=sharing\n",
        "\n",
        "You should just drag 'kaggle_3m' and 'all_data.csv' into your 'My Drive'."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HwRKEPOwKPhQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1d706be4-d370-44e1-ce6e-bd9dd7ae8ed7"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "#the path has kaggle_3m and all_data.csv\n",
        "default_path = \"/content/gdrive/My Drive\"\n",
        "\n",
        "#create a file for saving model\n",
        "model_path = \"/content/gdrive/My Drive/AnoAAE\"\n",
        "os.makedirs(model_path,exist_ok=True)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MA5dgeUkyuA2"
      },
      "source": [
        "#################################################################################\n",
        "# reference: https://www.kaggle.com/bonhart/brain-mri-data-visualization-unet-fpn\n",
        "#################################################################################\n",
        "# Raw data\n",
        "\n",
        "#if you have all_data.csv, please set read_df_csv=True.\n",
        "read_df_csv=True\n",
        "\n",
        "# Adding A/B column for diagnosis\n",
        "def positiv_negativ_diagnosis(mask_path):\n",
        "    value = np.max(cv2.imread(mask_path))\n",
        "    if value > 0 : return 1\n",
        "    else: return 0\n",
        "\n",
        "if read_df_csv:\n",
        "    df = pd.read_csv(default_path+\"/all_data.csv\")\n",
        "else:\n",
        "    data_map = []\n",
        "    for sub_dir_path in glob.glob(default_path+\"/kaggle_3m/*\"):\n",
        "        if os.path.isdir(sub_dir_path):\n",
        "            dirname = sub_dir_path.split(\"/\")[-1]\n",
        "            for filename in os.listdir(sub_dir_path):\n",
        "                image_path = sub_dir_path + \"/\" + filename\n",
        "                data_map.extend([dirname, image_path])\n",
        "        else:\n",
        "            print(\"This is not a dir:\", sub_dir_path)\n",
        "    print(\"Generating data list. Please wait for 30 minutes...\")\n",
        "    df = pd.DataFrame({\"dirname\" : data_map[::2],\n",
        "                      \"path\" : data_map[1::2]})\n",
        "    df.head()\n",
        "    # Masks/Not masks\n",
        "    df_imgs = df[~df['path'].str.contains(\"mask\")]\n",
        "    df_masks = df[df['path'].str.contains(\"mask\")]\n",
        "    base_len = 75\n",
        "    # Data sorting\n",
        "    imgs = sorted(df_imgs[\"path\"].values, key=lambda x : int(x[base_len:-4]))\n",
        "    masks = sorted(df_masks[\"path\"].values, key=lambda x : int(x[base_len:-9]))\n",
        "    # Final dataframe\n",
        "    df = pd.DataFrame({\"patient\": df_imgs.dirname.values,\n",
        "                       \"image_path\": imgs,\n",
        "                       \"mask_path\": masks})\n",
        "    df[\"diagnosis\"] = df[\"mask_path\"].apply(lambda m: positiv_negativ_diagnosis(m))\n",
        "    if not os.path.exists(default_path+\"/all_data.csv\"):\n",
        "        df.to_csv(default_path+\"/all_data.csv\")\n",
        "\n",
        "\n",
        "df_p = df[df['diagnosis']==0]\n",
        "df_n = df[df['diagnosis']==1]"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T9dZckLeyv9T"
      },
      "source": [
        "#CNN model\n",
        "class Generator(nn.Module):\n",
        "    def __init__(self, opt):\n",
        "        super().__init__()\n",
        "\n",
        "        self.init_size = opt.img_size // 4\n",
        "        self.l1 = nn.Sequential(nn.Linear(opt.latent_dim,\n",
        "                                128 * self.init_size ** 2))\n",
        "\n",
        "        self.conv_blocks = nn.Sequential(\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.Upsample(scale_factor=2),\n",
        "            nn.Conv2d(128, 128, 3, stride=1, padding=1),\n",
        "            nn.BatchNorm2d(128, 0.8),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            nn.Upsample(scale_factor=2),\n",
        "            nn.Conv2d(128, 64, 3, stride=1, padding=1),\n",
        "            nn.BatchNorm2d(64, 0.8),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            nn.Conv2d(64, opt.channels, 3, stride=1, padding=1),\n",
        "            nn.Tanh(),\n",
        "        )\n",
        "\n",
        "    def forward(self, z):\n",
        "        out = self.l1(z)\n",
        "        out = out.view(out.shape[0], 128, self.init_size, self.init_size)\n",
        "        img = self.conv_blocks(out)\n",
        "        return img\n",
        "\n",
        "class Discriminator(nn.Module):  \n",
        "    def __init__(self,opt):\n",
        "        super().__init__()\n",
        "        self.lin1 = nn.Linear(opt.latent_dim, 40)\n",
        "        self.drop1 = nn.Dropout2d(0.25)\n",
        "        self.act1 = nn.LeakyReLU(0.2, inplace=True)\n",
        "        self.lin2 = nn.Linear(40, 40*2)\n",
        "        self.drop2 = nn.Dropout2d(0.25)\n",
        "        self.act2 = nn.LeakyReLU(0.2, inplace=True)\n",
        "        self.lin3 = nn.Linear(40*2, 1)\n",
        "        self.act3 = nn.Identity()\n",
        "        #self.act4 = nn.Sigmoid()\n",
        "    def forward(self, x):\n",
        "        x = self.drop1(self.lin1(x))\n",
        "        x = self.act1(x)\n",
        "        x = self.drop2(self.lin2(x))\n",
        "        x = self.act2(x)\n",
        "        x = self.lin3(x)\n",
        "        x = self.act3(x)\n",
        "        output = x\n",
        "        #output = self.act4(x)\n",
        "        return output,x\n",
        "\n",
        "\n",
        "class Encoder(nn.Module):\n",
        "    def __init__(self, opt):\n",
        "        super().__init__()\n",
        "\n",
        "        def encoder_block(in_filters, out_filters, bn=True):\n",
        "            block = [nn.Conv2d(in_filters, out_filters, 3, 2, 1),\n",
        "                     nn.LeakyReLU(0.2, inplace=True), nn.Dropout2d(0.25)]\n",
        "            if bn:\n",
        "                block.append(nn.BatchNorm2d(out_filters, 0.8))\n",
        "            return block\n",
        "\n",
        "        self.model = nn.Sequential(\n",
        "            *encoder_block(opt.channels, 16, bn=False),\n",
        "            *encoder_block(16, 32),\n",
        "            *encoder_block(32, 64),\n",
        "            *encoder_block(64, 128),\n",
        "        )\n",
        "\n",
        "\n",
        "\n",
        "        # The height and width of downsampled image\n",
        "        ds_size = opt.img_size // 2 ** 4\n",
        "        self.adv_layer = nn.Sequential(nn.Linear(128 * ds_size ** 2,\n",
        "                                                 opt.latent_dim),\n",
        "                                       nn.Identity())\n",
        "        \n",
        "    def forward(self, img):\n",
        "        features = self.model(img)\n",
        "        features = features.view(features.shape[0], -1)\n",
        "        validity = self.adv_layer(features)\n",
        "        return validity"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xu1KxU2H0FFM"
      },
      "source": [
        "#load Dataset\n",
        "class BrainMriDataset(Dataset):\n",
        "    def __init__(self, df, transforms):\n",
        "        \n",
        "        self.df = df\n",
        "        self.transforms = transforms\n",
        "        \n",
        "    def __len__(self):\n",
        "        return len(self.df)\n",
        "    \n",
        "    def __getitem__(self, idx):\n",
        "        image = cv2.imread(self.df.iloc[idx, -3],cv2.IMREAD_GRAYSCALE)\n",
        "        image = Image.fromarray(image)\n",
        "        label = self.df.iloc[idx, -1]\n",
        "        if self.transforms:\n",
        "            image = self.transforms(image)\n",
        "        mask = cv2.imread(self.df.iloc[idx, -2],cv2.IMREAD_GRAYSCALE)\n",
        "        mask = Image.fromarray(mask)\n",
        "        if self.transforms:\n",
        "            mask = self.transforms(mask)\n",
        " \n",
        "        return image,label,mask"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-t_PAQNBLvTE"
      },
      "source": [
        "# Train AAE"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cvvBYyZy0JUc"
      },
      "source": [
        "#gradient penalty computation of WGAN-GP\n",
        "lambda_gp = 10\n",
        "def compute_gradient_penalty(D, real_samples, fake_samples, device):\n",
        "    \"\"\"Calculates the gradient penalty loss for WGAN GP\"\"\"\n",
        "    # Random weight term for interpolation between real and fake samples\n",
        "    alpha = torch.rand(*real_samples.shape[:2], 1, 1, device=device)\n",
        "    # Get random interpolation between real and fake samples\n",
        "    interpolates = (alpha * real_samples + (1 - alpha) * fake_samples)\n",
        "    interpolates = autograd.Variable(interpolates, requires_grad=True)\n",
        "    d_i_output,d_interpolates = D(interpolates)\n",
        "    fake = torch.ones(*d_interpolates.shape, device=device)\n",
        "    # Get gradient w.r.t. interpolates\n",
        "    gradients = autograd.grad(outputs=d_interpolates, inputs=interpolates,\n",
        "                              grad_outputs=fake, create_graph=True,\n",
        "                              retain_graph=True, only_inputs=True)[0]\n",
        "    gradients = gradients.view(gradients.shape[0], -1)\n",
        "    gradient_penalty = ((gradients.norm(2, dim=1) - 1) ** 2).mean()\n",
        "    return gradient_penalty\n",
        "\n",
        "#weight initialization\n",
        "def truncated_normal_(tensor,mean=0,std=0.09):\n",
        "    with torch.no_grad():\n",
        "        size = tensor.shape\n",
        "        tmp = tensor.new_empty(size+(4,)).normal_()\n",
        "        valid = (tmp < 2) & (tmp > -2)\n",
        "        ind = valid.max(-1, keepdim=True)[1]\n",
        "        tensor.data.copy_(tmp.gather(-1, ind).squeeze(-1))\n",
        "        tensor.data.mul_(std).add_(mean)\n",
        "    return tensor\n",
        "\n",
        "def weight_init(net):\n",
        "    for op in net.modules():\n",
        "        if isinstance(op,nn.Conv2d):\n",
        "            op.weight.data=truncated_normal_(op.weight.data,std=0.02)\n",
        "            nn.init.constant_(op.bias.data, val=0)\n",
        "        else:\n",
        "            pass\n",
        "\n",
        "#train aae\n",
        "def train(opt,load_model=False):\n",
        "    if type(opt.seed) is int:\n",
        "        torch.manual_seed(opt.seed)\n",
        "    print(torch.cuda.get_device_name(0))\n",
        "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "    \n",
        "\n",
        "    transform = transforms.Compose([transforms.Resize([opt.img_size]*2),\n",
        "                                    transforms.RandomHorizontalFlip(),\n",
        "                                    transforms.ToTensor()])\n",
        "    train_df = df_p.reset_index(drop=True)\n",
        "    train_dataset = BrainMriDataset(df=train_df, transforms=transform)\n",
        "    train_dataloader = DataLoader(train_dataset, batch_size=opt.batch_size,shuffle=True)\n",
        "    generator = Generator(opt)\n",
        "    discriminator = Discriminator(opt)\n",
        "    encoder = Encoder(opt)\n",
        "\n",
        "    weight_init(generator)\n",
        "    weight_init(discriminator)\n",
        "    weight_init(encoder)\n",
        "\n",
        "\n",
        "    generator.to(device)\n",
        "    discriminator.to(device)\n",
        "    encoder.to(device)\n",
        "\n",
        "    # optimizers\n",
        "    #optim_Gen = torch.optim.Adam(generator.parameters(), lr=opt.lr, betas=(opt.b1, opt.b2))\n",
        "    optim_Dec = torch.optim.Adam(generator.parameters(), lr=opt.lr, betas=(opt.b1, opt.b2))\n",
        "    optim_Enc = torch.optim.Adam(encoder.parameters(), lr=opt.lr, betas=(opt.b1, opt.b2))\n",
        "    optim_Dis = torch.optim.Adam(discriminator.parameters(), lr=opt.lr, betas=(opt.b1, opt.b2))\n",
        "\n",
        "    writer = SummaryWriter(model_path+'/tensorboard')\n",
        "\n",
        "    print(\"Training..\")\n",
        "\n",
        "    for epoch in range(opt.n_epochs):\n",
        "        begin_time = time.time()\n",
        "        for i,(imgs,_lbl,_msk) in enumerate(train_dataloader):\n",
        "            real_imgs = imgs.to(device)\n",
        "            real_z = torch.randn(imgs.shape[0], opt.latent_dim, device=device)\n",
        "            optim_Enc.zero_grad()\n",
        "            optim_Dec.zero_grad()\n",
        "            optim_Dis.zero_grad()\n",
        "\n",
        "            # reconstruct\n",
        "            encoder_output=encoder(real_imgs)\n",
        "            output = generator(encoder_output)\n",
        "            autoencoder_loss = torch.mean(torch.sqrt(torch.sum(torch.square(output - real_imgs),[1, 2, 3])))\n",
        "\n",
        "            #l2 loss\n",
        "            l2_loss = nn.MSELoss()\n",
        "            reconstruct_loss_l2 = l2_loss(real_imgs,output)\n",
        "            reconstruct_loss = autoencoder_loss+0.5*reconstruct_loss_l2\n",
        "            reconstruct_loss.backward()\n",
        "\n",
        "            optim_Enc.step()\n",
        "            optim_Dec.step()\n",
        "\n",
        "            # discriminator\n",
        "            encoder.eval()\n",
        "            \n",
        "            with torch.no_grad():\n",
        "                z_fake = encoder(real_imgs)\n",
        "            real_d,real_logits = discriminator(real_z)\n",
        "            fake_d,fake_logits = discriminator(z_fake)\n",
        "            gradient_penalty = compute_gradient_penalty(discriminator,\n",
        "                                                        real_z.data,\n",
        "                                                        z_fake.data,\n",
        "                                                        device)\n",
        "            d_loss = -torch.mean(real_logits) + torch.mean(fake_logits) + lambda_gp * gradient_penalty\n",
        "            d_loss.backward()\n",
        "            optim_Dis.step()\n",
        "\n",
        "            # encoder\n",
        "            encoder.train()\n",
        "            z_fake = encoder(real_imgs)\n",
        "            e_fake,e_fake_logits = discriminator(z_fake)\n",
        "            e_loss = -torch.mean(e_fake_logits)\n",
        "            #g_loss = -torch.mean(torch.log(e_fake_logits + 1e-8))\n",
        "            e_loss.backward()\n",
        "            optim_Enc.step()\n",
        "\n",
        "            #print(f\"[Epoch {epoch}/{opt.n_epochs}] \"\n",
        "            #      f\"[Batch {i}/{len(train_dataloader)}] \"\n",
        "            #      f\"[R loss: {reconstruct_loss.item():3f}] \"\n",
        "            #      f\"[D loss: {d_loss.item():3f}] \"\n",
        "            #      f\"[G loss: {g_loss.item():3f}]\")\n",
        "\n",
        "            #visualization\n",
        "            writer.add_scalar('Reconstruction Loss',reconstruct_loss,epoch*opt.batch_size+i)\n",
        "            writer.add_scalar('Discriminator Loss',d_loss,epoch*opt.batch_size+i)\n",
        "            writer.add_scalar('Encoder Loss',e_loss,epoch*opt.batch_size+i)\n",
        "            writer.add_histogram('Encoder Distribution',encoder_output,epoch*opt.batch_size+i)\n",
        "            writer.add_histogram('Real Distribution',real_z,epoch*opt.batch_size+i)\n",
        "            #print(torch.max(real_imgs[0]))\n",
        "            #print(torch.min(real_imgs[0]))\n",
        "            #print(torch.max(output[0]))\n",
        "            #print(torch.min(output[0]))\n",
        "            input_image = real_imgs[0].reshape(opt.channels,opt.img_size,opt.img_size)\n",
        "            generate_image = output[0].reshape(opt.channels,opt.img_size,opt.img_size)\n",
        "            writer.add_image('input image',input_image,epoch*opt.batch_size+i)\n",
        "            writer.add_image('generate image',generate_image,epoch*opt.batch_size+i)\n",
        "        print(f\"[Epoch {epoch}/{opt.n_epochs}] \"\n",
        "              f\"[R loss: {reconstruct_loss.item():3f}] \"\n",
        "              f\"[D loss: {d_loss.item():3f}] \"\n",
        "              f\"[G loss: {e_loss.item():3f}]\")\n",
        "    torch.save(generator.state_dict(), model_path + \"\\aae_generator.pth\")\n",
        "    torch.save(discriminator.state_dict(), model_path+\"\\aae_discriminator.pth\")\n",
        "    torch.save(encoder.state_dict(), model_path+\"\\aae_encoder.pth\")"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ztmkEsBgBK45",
        "outputId": "f0b695a7-f3a8-4fd9-fc17-d121f6a63fff"
      },
      "source": [
        "if __name__ == \"__main__\":\n",
        "    import argparse\n",
        "    parser = argparse.ArgumentParser()\n",
        "    parser.add_argument(\"--n_epochs\", type=int, default=300,\n",
        "                        help=\"number of epochs of training\")\n",
        "    parser.add_argument(\"--batch_size\", type=int, default=32,\n",
        "                        help=\"size of the batches\")\n",
        "    parser.add_argument(\"--lr\", type=float, default=0.0002,\n",
        "                        help=\"adam: learning rate\")\n",
        "    parser.add_argument(\"--b1\", type=float, default=0.5,\n",
        "                        help=\"adam: decay of first order momentum of gradient\")\n",
        "    parser.add_argument(\"--b2\", type=float, default=0.999,\n",
        "                        help=\"adam: decay of first order momentum of gradient\")\n",
        "    parser.add_argument(\"--latent_dim\", type=int, default=100,\n",
        "                        help=\"dimensionality of the latent space\")\n",
        "    parser.add_argument(\"--img_size\", type=int, default=64,\n",
        "                        help=\"size of each image dimension\")\n",
        "    parser.add_argument(\"--channels\", type=int, default=3,\n",
        "                        help=\"number of image channels\")\n",
        "    parser.add_argument(\"--seed\", type=int, default=None,\n",
        "                        help=\"value of a random seed\")\n",
        "    opt = parser.parse_args(['--seed',str(1),'--n_epochs',str(3000),'--lr',str(1e-4),\n",
        "                             '--img_size',str(64),'--latent_dim',str(128),\n",
        "                             '--channels',str(1)])\n",
        "\n",
        "    train(opt)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tesla T4\n",
            "Training..\n",
            "[Epoch 0/3000] [R loss: 3.792454] [D loss: 67.356903] [G loss: 0.075394]\n",
            "[Epoch 1/3000] [R loss: 3.996897] [D loss: 28.676685] [G loss: 0.081016]\n",
            "[Epoch 2/3000] [R loss: 3.712724] [D loss: 17.830408] [G loss: 0.082219]\n",
            "[Epoch 3/3000] [R loss: 3.556369] [D loss: 12.648266] [G loss: 0.092498]\n",
            "[Epoch 4/3000] [R loss: 3.429359] [D loss: 7.290919] [G loss: 0.096107]\n",
            "[Epoch 5/3000] [R loss: 3.252504] [D loss: 4.877563] [G loss: 0.100359]\n",
            "[Epoch 6/3000] [R loss: 2.951897] [D loss: 3.842360] [G loss: 0.098423]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_xd5LWxnL0kX"
      },
      "source": [
        "# Test & Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NfTXdGROeBO6"
      },
      "source": [
        "def BinaryConfusionMatrix(prediction, groundtruth):\n",
        "    \"\"\"Computes scores:\n",
        "    TP = True Positives  \n",
        "    FP = False Positives   \n",
        "    FN = False Negatives   \n",
        "    TN = True Negatives    \n",
        "    return: TP, FP, FN, TN\"\"\"\n",
        " \n",
        "    TP = np.float(np.sum((prediction == 1) & (groundtruth == 1)))\n",
        "    FP = np.float(np.sum((prediction == 1) & (groundtruth == 0)))\n",
        "    FN = np.float(np.sum((prediction == 0) & (groundtruth == 1)))\n",
        "    TN = np.float(np.sum((prediction == 0) & (groundtruth == 0)))\n",
        " \n",
        "    return TN, FP, FN,TP\n",
        "    \n",
        "def get_dice(prediction, groundtruth):\n",
        "    TN, FP, FN,TP = BinaryConfusionMatrix(prediction, groundtruth)    \n",
        "    dice = 2 * float(TP)/(float(FP + 2 * TP + FN) + 1e-6)\n",
        "    return dice\n",
        "\n",
        "def evaluation(ano_score,ano_mask,mask,plot_curve = False):\n",
        "    #############\n",
        "    # Dice sore #\n",
        "    #############\n",
        "    dice_score = get_dice(ano_mask.reshape(-1).astype(int), \n",
        "                          mask.reshape(-1).astype(int))\n",
        "    #print(\"Dice Score:\",dice_score)\n",
        "    #############\n",
        "    #   AUROC   #\n",
        "    #############\n",
        "    auroc = roc_auc_score(mask.reshape(-1).astype(int), ano_score.reshape(-1))\n",
        "    #print(\"AUROC:\",auroc)\n",
        "    if plot_curve==True:\n",
        "        fpr, tpr, _ = roc_curve(mask.reshape(-1).astype(int), ano_score.reshape(-1))\n",
        "        roc_auc = auc(fpr, tpr)\n",
        "        plt.figure()\n",
        "        lw = 2\n",
        "        plt.plot(fpr, tpr, color='darkorange',\n",
        "                 lw=lw, label='ROC curve (area = %0.2f)' % roc_auc)\n",
        "        plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')\n",
        "        plt.xlim([0.0, 1.0])\n",
        "        plt.ylim([0.0, 1.05])\n",
        "        plt.xlabel('False Positive Rate')\n",
        "        plt.ylabel('True Positive Rate')\n",
        "        plt.title('Receiver operating characteristic')\n",
        "        plt.legend(loc=\"lower right\")\n",
        "        plt.show()\n",
        "    #############\n",
        "    #   AUPRC   #\n",
        "    #############\n",
        "    auprc = average_precision_score(mask.reshape(-1).astype(int),ano_score.reshape(-1))\n",
        "    #print(\"AUPRC:\",auprc)\n",
        "    if plot_curve==True:\n",
        "        precision,recall,_ = precision_recall_curve(mask.reshape(-1).astype(int),ano_score.reshape(-1))\n",
        "        plt.figure()\n",
        "        lw = 2\n",
        "        plt.plot(recall, precision, color='darkorange',\n",
        "                 lw=lw, label='PR curve (area = %0.2f)' % auprc)\n",
        "        plt.xlim([0.0, 1.0])\n",
        "        plt.ylim([0.0, 1.05])\n",
        "        plt.xlabel('Recall')\n",
        "        plt.ylabel('Precision')\n",
        "        plt.title('Precision-Recall curve')\n",
        "        plt.legend(loc=\"lower right\")\n",
        "        plt.show()\n",
        "    return dice_score,auroc,auprc\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "buqLN--Ij8g0"
      },
      "source": [
        "def test(opt,load_model=True):\n",
        "    if type(opt.seed) is int:\n",
        "        torch.manual_seed(opt.seed)\n",
        "    print(torch.cuda.get_device_name(0))\n",
        "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "    \n",
        "\n",
        "    transform = transforms.Compose([transforms.Resize([opt.img_size]*2),\n",
        "                                    #transforms.RandomHorizontalFlip(),\n",
        "                                    transforms.ToTensor()\n",
        "                                    ])\n",
        "    #df_test = pd.concat([df_p[-1373:],df_n],axis=0,ignore_index=True)\n",
        "    #print(df_test)\n",
        "\n",
        "    test_df = df_n.reset_index(drop=True)\n",
        "    test_dataset = BrainMriDataset(df=test_df, transforms=transform)\n",
        "    test_dataloader = DataLoader(test_dataset, batch_size=opt.batch_size,shuffle=True)\n",
        "    generator = Generator(opt).to(device)\n",
        "    discriminator = Discriminator(opt).to(device)\n",
        "    encoder = Encoder(opt).to(device)\n",
        "    generator.load_state_dict(torch.load(model_path+ \"\\aae_generator.pth\"))\n",
        "    discriminator.load_state_dict(torch.load(model_path + \"\\aae_discriminator.pth\"))\n",
        "    encoder.load_state_dict(torch.load(model_path + \"\\aae_encoder.pth\"))\n",
        "    %matplotlib inline\n",
        "    dice_score = 0\n",
        "    auroc=0\n",
        "    auprc=0\n",
        "    count = 0\n",
        "    for ind,(img, label,mask) in enumerate(test_dataloader):\n",
        "        #Add FLAIR feature\n",
        "        #img_flair = 1-np.multiply(1-img,1-mask)\n",
        "        img_flair = np.multiply(img,1-mask)+np.multiply(img,mask)*1.6\n",
        "        #Generate normal image and anomaly region\n",
        "        img_z = encoder(img_flair.to(device))\n",
        "        img_g = generator(img_z)\n",
        "        img_ano = img_flair.to(device)-img_g\n",
        "        #generate anomaly mask\n",
        "        ano_mask = []\n",
        "        for i in range(img.shape[0]):\n",
        "            ano_img = img_ano[i].cpu().detach().numpy().squeeze()\n",
        "            ret,thresh_img = cv2.threshold(ano_img,np.max(ano_img)/2.2,1,cv2.THRESH_BINARY)\n",
        "            ano_mask.append(thresh_img)\n",
        "        #normalize anomaly region image\n",
        "        ano_score = img_ano.cpu().detach().numpy().reshape(32,-1)\n",
        "        minmax_scaler = preprocessing.MinMaxScaler() \n",
        "        ano_score = minmax_scaler.fit_transform(ano_score)\n",
        "        #evaluation\n",
        "        dice,roc,prc = evaluation(ano_score,np.array(ano_mask),mask.numpy())\n",
        "        dice_score+=dice\n",
        "        auroc+=roc\n",
        "        auprc+=prc\n",
        "        print('Evaluating:',count)\n",
        "        count+=1\n",
        "    dice_score = dice_score/count\n",
        "    auroc = auroc/count\n",
        "    auprc = auprc/count\n",
        "    print('Dice score:',dice_score)\n",
        "    print('AUROC:',auroc)\n",
        "    print('auprc:',auprc)\n",
        "\n",
        "\n",
        "    #Visualization the first batch\n",
        "    for ind,(img, label,mask) in enumerate(test_dataloader):\n",
        "        plt.figure(figsize=(10, 10))\n",
        "        for i in range(32):\n",
        "            ax = plt.subplot(4, 8, i + 1)\n",
        "            plt.imshow(img[i].squeeze(),cmap ='gray')\n",
        "            plt.axis(\"off\")\n",
        "        plt.show()\n",
        "        print(\"=================================================================\")\n",
        "        #img_flair = 1-np.multiply(1-img,1-mask)\n",
        "        img_flair = np.multiply(img,1-mask)+np.multiply(img,mask)*1.6\n",
        "        plt.figure(figsize=(10, 10))\n",
        "        for i in range(32):\n",
        "            ax = plt.subplot(4, 8, i + 1)\n",
        "            plt.imshow(img_flair[i].squeeze(),cmap ='gray')\n",
        "            plt.axis(\"off\")\n",
        "        #plt.savefig(path+\"AnoAAE_results/\"+\"img_flair\"+\".jpg\")\n",
        "        plt.show()\n",
        "        print(\"=================================================================\")\n",
        "        img_z = encoder(img_flair.to(device))\n",
        "        img_g = generator(img_z)\n",
        "        img_ano = img_flair.to(device)-img_g\n",
        "        plt.figure(figsize=(10, 10))\n",
        "        for i in range(32):\n",
        "            ax = plt.subplot(4, 8, i + 1)\n",
        "            plt.imshow(img_g[i].cpu().detach().numpy().squeeze(),cmap ='gray')\n",
        "            plt.axis(\"off\")\n",
        "        #plt.savefig(path+\"AnoAAE_results/\"+\"img_g\"+\".jpg\")\n",
        "        plt.show()\n",
        "        print(\"=================================================================\")\n",
        "        plt.figure(figsize=(10, 10))\n",
        "        for i in range(32):\n",
        "            ax = plt.subplot(4, 8, i + 1)\n",
        "            plt.imshow(mask[i].cpu().detach().numpy()[0].squeeze(),cmap ='gray')\n",
        "            plt.axis(\"off\")\n",
        "        #plt.savefig(path+\"AnoAAE_results/\"+\"mask\"+\".jpg\")\n",
        "        plt.show()\n",
        "        print(\"=================================================================\")\n",
        "        plt.figure(figsize=(10, 10))\n",
        "        ano_score = []\n",
        "        ano_mask = []\n",
        "        for i in range(32):\n",
        "            ax = plt.subplot(4, 8, i + 1)\n",
        "            ano_img = img_ano[i].cpu().detach().numpy().squeeze()\n",
        "            ret,thresh_img = cv2.threshold(ano_img,np.max(ano_img)/2.2,1,cv2.THRESH_BINARY)\n",
        "            ano_score.append(ano_img)\n",
        "            ano_mask.append(thresh_img)\n",
        "            plt.imshow(thresh_img,cmap ='gray')\n",
        "            plt.axis(\"off\")\n",
        "        #plt.savefig(path+\"AnoAAE_results/\"+\"ano_mask\"+\".jpg\")\n",
        "        plt.show()\n",
        "        print(\"=================================================================\")\n",
        "\n",
        "        ano_score = np.array(ano_score).reshape(32,-1)\n",
        "        minmax_scaler = preprocessing.MinMaxScaler() \n",
        "        ano_score = minmax_scaler.fit_transform(ano_score)\n",
        "\n",
        "        dice_score,auroc,auprc=evaluation(ano_score,np.array(ano_mask),mask.numpy(),True)\n",
        "        break\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    import argparse\n",
        "    parser = argparse.ArgumentParser()\n",
        "    parser.add_argument(\"--n_epochs\", type=int, default=300,\n",
        "                        help=\"number of epochs of training\")\n",
        "    parser.add_argument(\"--batch_size\", type=int, default=32,\n",
        "                        help=\"size of the batches\")\n",
        "    parser.add_argument(\"--lr\", type=float, default=0.0002,\n",
        "                        help=\"adam: learning rate\")\n",
        "    parser.add_argument(\"--b1\", type=float, default=0.5,\n",
        "                        help=\"adam: decay of first order momentum of gradient\")\n",
        "    parser.add_argument(\"--b2\", type=float, default=0.999,\n",
        "                        help=\"adam: decay of first order momentum of gradient\")\n",
        "    parser.add_argument(\"--latent_dim\", type=int, default=100,\n",
        "                        help=\"dimensionality of the latent space\")\n",
        "    parser.add_argument(\"--img_size\", type=int, default=64,\n",
        "                        help=\"size of each image dimension\")\n",
        "    parser.add_argument(\"--channels\", type=int, default=3,\n",
        "                        help=\"number of image channels\")\n",
        "    parser.add_argument(\"--seed\", type=int, default=None,\n",
        "                        help=\"value of a random seed\")\n",
        "    opt = parser.parse_args(['--seed',str(1),'--n_epochs',str(3000),'--lr',str(1e-4),\n",
        "                             '--img_size',str(64),'--latent_dim',str(128),\n",
        "                             '--channels',str(1)])\n",
        "    test(opt,True)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IzZgjO7yL4zN"
      },
      "source": [
        "# Visualize the training curve"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BKTMezHdqE5M"
      },
      "source": [
        "%load_ext tensorboard\n",
        "%tensorboard --logdir=model_path+'/tensorboard' --host=127.0.0.1"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}